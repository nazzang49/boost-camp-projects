{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(P09)GPT_fine_tuning_practice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nazzang49/boost-camp-projects/blob/main/assignments/(P09)GPT_fine_tuning_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvZWRYXfrPoC"
      },
      "source": [
        "# 한국어 언어모델 학습 및 다중 과제 튜닝\n",
        "## KoGPT-2 기반의 챗봇 실습\n",
        "\n",
        "> 작성자      \n",
        "```\n",
        "* 김성현 (bananaband657@gmail.com)  \n",
        "1기 멘토\n",
        "김바다 (qkek983@gmail.com)\n",
        "박상희 (parksanghee0103@gmail.com)  \n",
        "이정우 (jungwoo.l2.rs@gmail.com)\n",
        "2기 멘토\n",
        "박상희 (parksanghee0103@gmail.com)  \n",
        "이정우 (jungwoo.l2.rs@gmail.com)\n",
        "이녕우 (leenw2@gmail.com)\n",
        "박채훈 (qkrcogns2222@gmail.com)\n",
        "```\n",
        "[CC BY-NC-ND](https://creativecommons.org/licenses/by-nc-nd/2.0/kr/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-MEs10aspvP"
      },
      "source": [
        "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n",
        "!apt-get install git-lfs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mY77fpbBsdSt",
        "outputId": "38fdf68e-afb1-4c43-b84f-a28bce63c20f"
      },
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/taeminlee/kogpt2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into 'kogpt2'...\n",
            "remote: Enumerating objects: 52, done.\u001b[K\n",
            "remote: Counting objects: 100% (52/52), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 52 (delta 20), reused 0 (delta 0)\u001b[K\n",
            "Unpacking objects: 100% (52/52), done.\n",
            "Filtering content: 100% (2/2), 959.93 MiB | 64.77 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fqPpH5tjaGU"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQ53aod3te4S"
      },
      "source": [
        "import torch\n",
        "from tokenizers import SentencePieceBPETokenizer\n",
        "from transformers import GPT2Config, GPT2LMHeadModel\n",
        "\n",
        "tokenizer = SentencePieceBPETokenizer(\"/content/kogpt2/vocab.json\", \"/content/kogpt2/merges.txt\")\n",
        "\n",
        "config = GPT2Config(vocab_size=50000)\n",
        "model = GPT2LMHeadModel(config)\n",
        "\n",
        "model_dir = '/content/kogpt2/pytorch_model.bin'\n",
        "\n",
        "model.load_state_dict(torch.load(model_dir, map_location='cuda'), strict=False)\n",
        "model.to('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmbeAIR9tppB",
        "outputId": "6a2125b0-388b-4612-fc59-3f542ef7c35e"
      },
      "source": [
        "tokenized_text = tokenizer.encode('이순신은 조선 중기의 무신이다.', add_special_tokens=True)\n",
        "print(tokenized_text)\n",
        "print(tokenized_text.tokens)\n",
        "print(tokenized_text.ids)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding(num_tokens=7, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
            "['▁이순', '신은', '▁조선', '▁중기의', '▁무신', '이다', '.']\n",
            "[10925, 6647, 1117, 40249, 39793, 128, 47440]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSoQlsfcn0ct",
        "outputId": "f8d0cd75-de7c-4d55-8c90-bd00cd3442f9"
      },
      "source": [
        "import torch\n",
        "torch.manual_seed(42)\n",
        "\n",
        "input_ids = torch.tensor(tokenizer.encode(\"이순신은\", add_special_tokens=True).ids).unsqueeze(0).to('cuda')\n",
        "\n",
        "output_sequences = model.generate(input_ids=input_ids, do_sample=True, max_length=100, num_return_sequences=3)\n",
        "for generated_sequence in output_sequences:\n",
        "    generated_sequence = generated_sequence.tolist()\n",
        "    print(\"GENERATED SEQUENCE : {0}\".format(tokenizer.decode(generated_sequence, skip_special_tokens=True)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED SEQUENCE : 이순신은 백옥담(이종원 분)의 시선으로 백성을 살피는 것을 알게 되었고, 천하에 대한 소신을 가지게 되었다.</s><s> 또한 성읍인 성전은 백옥담의 동생인 윤(尹)이 성전과 함께 있었는데 윤을 그의 아버지라고 불렀다.</s><s> 또한 성전이 완공될 때까지 성전에서 계속 놀 수 있었다.</s><s> 성전 안에서는 두 권의 도서가 있고, 이 문서에는 윤과 성국의 성전의 위치가 찍혀져 있다.\n",
            "GENERATED SEQUENCE : 이순신은 이미 태연에게 마음을 돌린 상태.</s><s> 이어 \"자칫 북한이 미사일 도발에 나설 수도 있다는 경고가 되고 있는 만큼 한미가 이에 대해 적절히 대응해주길 바란다\"고 당부했다.</s><s> 또한 \"오늘 김관진 제1위원장이 오랫만에 공개토론을 한 뒤 북한 도발을 중지하고 대화를 시작해야 한다고 강조한 것을 감안할 때 이번 주 미측과 한반도에서의 대화 분위기가 계속될 것으로 확신한다\"고 말했다.</s><s> 또한 김 제1위원장의 이번 방문에서 미국측에 한반도 신뢰프로세스 차원의\n",
            "GENERATED SEQUENCE : 이순신은 고려 왕조를 건국한 이성계 형 이인임부터 명나라로 이민을 온 고려 왕조에 이르기까지 다양한 인물상과 고려 역사를 사실 그대로 옮겨 적에게 전달하는 것이 중요한 사료다.</s><s> 이들은 모두 6명이고, 이중 6명은 유랑 생활을 한 이른바 ‘귀족’으로, 유랑 생활 5년 동안 ‘무덤덤’을 팠고, 이들은 유림의 한 사람인 목침을 써서 한방에서 술을 빚었다고 한다.</s><s> 목침은 조선시대 중종\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiMxKv3p_gys"
      },
      "source": [
        "## 데이터셋 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpWFdTaypWf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cdf80e7-75dd-4a0a-9bcd-d22505d2477e"
      },
      "source": [
        "!git clone https://github.com/songys/Chatbot_data.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Chatbot_data'...\n",
            "remote: Enumerating objects: 50, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 50 (delta 17), reused 2 (delta 1), pack-reused 18\u001b[K\n",
            "Unpacking objects: 100% (50/50), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEcJdwLl_iig"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/Chatbot_data/ChatbotData.csv')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUtOdLe8_k6Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "8b58d292-ef8f-4f86-a0dd-c6292c501bd8"
      },
      "source": [
        "# 질문 - 답변으로 이뤄진 데이터\n",
        "data.head(10)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SD카드 망가졌어</td>\n",
              "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>SD카드 안돼</td>\n",
              "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SNS 맞팔 왜 안하지ㅠㅠ</td>\n",
              "      <td>잘 모르고 있을 수도 있어요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n",
              "      <td>시간을 정하고 해보세요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
              "      <td>시간을 정하고 해보세요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Q                   A  label\n",
              "0                   12시 땡!          하루가 또 가네요.      0\n",
              "1              1지망 학교 떨어졌어           위로해 드립니다.      0\n",
              "2             3박4일 놀러가고 싶다         여행은 언제나 좋죠.      0\n",
              "3          3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠.      0\n",
              "4                  PPL 심하네          눈살이 찌푸려지죠.      0\n",
              "5                SD카드 망가졌어  다시 새로 사는 게 마음 편해요.      0\n",
              "6                  SD카드 안돼  다시 새로 사는 게 마음 편해요.      0\n",
              "7           SNS 맞팔 왜 안하지ㅠㅠ    잘 모르고 있을 수도 있어요.      0\n",
              "8  SNS 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요.      0\n",
              "9        SNS 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요.      0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yv0vF1ITD43q",
        "outputId": "5f30d36f-ef3e-4340-d2bc-bd0b646d2220"
      },
      "source": [
        "added_special_token_num = tokenizer.add_special_tokens(['<s>', '</s>'])\n",
        "print(added_special_token_num)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcjsvzsxaPuw",
        "outputId": "a969094b-724c-4567-eae5-7b06d3bd7141"
      },
      "source": [
        "pad_id = tokenizer.token_to_id(\"<pad>\")\n",
        "print(pad_id)\n",
        "tokenizer.enable_padding(pad_id=pad_id, pad_token=\"<pad>\") # padding 설정\n",
        "tokenizer.enable_truncation(max_length=128) # max length 설정"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBkBrz36Yoh3"
      },
      "source": [
        "class ChatDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, tokenizer, file_path):\n",
        "        self.data = []\n",
        "        self.file_path = file_path\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def load_data(self):\n",
        "        raw_data = pd.read_csv(self.file_path)\n",
        "        train_data = '<s>'+raw_data['Q']+'</s>'+'<s>'+raw_data['A']+'</s>' # 생성 패턴을 미리 알려주는 것과 동일한 효과\n",
        "        #<s>안녕하세요</s><s> -> 네, 안녕하세요</s>\n",
        "        tokenized_train_data = tokenizer.encode_batch(train_data) # 문장 토큰화 진행\n",
        "        for single_data in tokenized_train_data:\n",
        "            self.data.append(torch.tensor(single_data.ids).unsqueeze(0))\n",
        "                \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        item = self.data[index]\n",
        "        return item"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9ScRLNVK7yw"
      },
      "source": [
        "train_dataset = ChatDataset(tokenizer=tokenizer, file_path='/content/Chatbot_data/ChatbotData.csv')\n",
        "train_dataset.load_data()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9Ag7uCHTHrY",
        "outputId": "3ce625f3-8f43-4a5a-dce9-a0e4b219e483"
      },
      "source": [
        "train_dataset.data[:1]\n",
        "train_dataset.data[:1][0].shape\n",
        "\n",
        "# <s> => 0\n",
        "# </s> => 1\n",
        "# <pad> => 3\n",
        "\n",
        "# [tensor([[    0,   385, 47460, 47437, 49108, 47812,     1,     0, 33203,   252,\n",
        "#             119,  7974, 47440,     1,     3,     3,     3,     3,     3,     3,\n",
        "#               3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
        "#               3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
        "#               3,     3,     3,     3]])]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 44])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hofZW_kUcQsU"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "data_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoTb3cNocG-e"
      },
      "source": [
        "from transformers import AdamW"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSPCJzNZNfbD"
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr=1e-4, correct_bias=True)\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "avg_loss = (0.0, 0.0)\n",
        "for epoch in range(epochs):\n",
        "    count=0\n",
        "    for data in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        data = data.transpose(1,0)\n",
        "        data = data.to('cuda')\n",
        "        model = model.to('cuda')\n",
        "        \n",
        "        outputs = model(data, labels=data) # input = output => 모델은 입력된 문장의 토큰을 하나씩 추적하면서 다음 토큰 예측\n",
        "        loss, logits = outputs[:2] # idx 0 => loss / idx 1 => logits\n",
        "        loss = loss.to('cuda')\n",
        "        loss.backward()\n",
        "\n",
        "        avg_loss = (avg_loss[0] * 0.99 + loss, avg_loss[1] * 0.99 + 1.0)\n",
        "        optimizer.step()\n",
        "        if count % 200 == 0:\n",
        "            print('epoch no.{0}  train ({1}/{2})  loss = {3:.5f}  avg_loss = {4:.5f}' . format(epoch, count, len(data_loader), loss, avg_loss[0] / avg_loss[1]))\n",
        "        count += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNRmD2Gifjgd"
      },
      "source": [
        "torch.save(model.state_dict(), 'chitchat_model.bin')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVtv1Xtdg2Tm"
      },
      "source": [
        "def encoding(text):\n",
        "    text = '<s>'+text+'</s><s>' # <s> 이후 문장을 모델이 생성하게 됨 as output\n",
        "    return torch.tensor(tokenizer.encode(text).ids).unsqueeze(0).to('cuda')\n",
        "\n",
        "def decoding(ids):\n",
        "    return tokenizer.decode_batch(ids)\n",
        "\n",
        "tokenizer.no_padding()\n",
        "tokenizer.no_truncation()\n",
        "\n",
        "e_s = tokenizer.token_to_id('</s>')\n",
        "unk = tokenizer.token_to_id('<unk>')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThJtItZWxeEQ"
      },
      "source": [
        "def get_answer(input_sent):\n",
        "    input_ids = encoding(input_sent)\n",
        "\n",
        "    sample_outputs = model.generate(\n",
        "        input_ids,\n",
        "        num_return_sequences=5,\n",
        "        do_sample=True, \n",
        "        max_length=128, \n",
        "        top_k=50, \n",
        "        top_p=0.95, \n",
        "        eos_token_id=e_s,\n",
        "        early_stopping=True,\n",
        "        bad_words_ids=[[unk]] # list 형태로 token id 넣어주면 해당 토큰은 생성되지 않도록 모델이 피하게 됨\n",
        "    )\n",
        "\n",
        "    decoded_result = decoding(sample_outputs.tolist())\n",
        "    for result in decoded_result:\n",
        "        print(result)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9lKP5afxp1V",
        "outputId": "2fba4ca5-7f4e-4f11-8b55-fa3b7f48c4a0"
      },
      "source": [
        "get_answer('안녕?')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕? 안녕하세요.\n",
            "안녕? 안녕하세요.\n",
            "안녕? 안녕.\n",
            "안녕? 안녕하세요.\n",
            "안녕? 안녕하세요.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrS8l4fpxsWE",
        "outputId": "50fd290d-b5f0-45ea-e182-ee00645b1a06"
      },
      "source": [
        "get_answer('만나서 반가워.')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "만나서 반가워. 서로 사랑하나봅니다.\n",
            "만나서 반가워. 좋은 추억 만드시길 바랍니다.\n",
            "만나서 반가워. 서로를 반기는 마음을 표현해주세요.\n",
            "만나서 반가워. 저도 반가워요.\n",
            "만나서 반가워. 좋은 만남이었길 바라요.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIfx93gHxyuk",
        "outputId": "8afde0fc-6cc7-4371-9637-b2588c35a4a6"
      },
      "source": [
        "get_answer('인공지능의 미래에 대해 어떻게 생각하세요?')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인공지능의 미래에 대해 어떻게 생각하세요? 인공지능에 물들어 가는게 제일 두렵지 않아요. 인공지능이 우리를 지배하고 있어요. 인공지능이 우리를 이어주는 한켠에 있기 때문 아닐까요. 인공지능에 대한 두려움을 가지고 있으면서도 두려움을 가지고 있을 수 있어요.\n",
            "인공지능의 미래에 대해 어떻게 생각하세요? 인공지능이 모든 일에 큰 영향을 미칠거예요. 인공지능에 대한 관심이 필요한 시기예요. 인공지능에 대한 관심이 필요한 시기이기도 합니다.\n",
            "인공지능의 미래에 대해 어떻게 생각하세요? 인공지능은 이미 많은 발전이 되었어요.\n",
            "인공지능의 미래에 대해 어떻게 생각하세요? 인공지능은 지금 엄청 천재 수준이에요.\n",
            "인공지능의 미래에 대해 어떻게 생각하세요? 제가 말씀 드릴게요. 인공지능이 될 인공지능에 대해 이야기 해드릴게요. 인공지능에 대해 이야기할게요.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxyDnMtjx86O",
        "outputId": "2d487225-a6f1-4f56-d844-83d8e3dcc0ff"
      },
      "source": [
        "get_answer('여자친구 선물 추천해줘.')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "여자친구 선물 추천해줘. 어떤 게 좋을까요.\n",
            "여자친구 선물 추천해줘. 작은 선물은 당신을 축복합니다.\n",
            "여자친구 선물 추천해줘. 부담스럽지 않은 선이 좋겠어요.\n",
            "여자친구 선물 추천해줘. 같이 먹으세요.\n",
            "여자친구 선물 추천해줘. 부담스럽지 않은 선이 좋겠어요.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaAJlFlDyGSp",
        "outputId": "ba376482-c0e1-42f4-ed41-c29251798e60"
      },
      "source": [
        "get_answer('앞으로 인공지능이 어떻게 발전하게 될까요?')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "앞으로 인공지능이 어떻게 발전하게 될까요? 인공지능에 대한 지식이 있으신가 봐요. 인공지능에 대한 지식이 없네요. 인공지능이 탄생할거예요. 인공지능에 대한 지식이 필요 없더라도 인공지능을 이해할 수 있어요. 인공지능을 보면서 인공지능에 대한 지식이 필요한 순간이 왔네요.\n",
            "앞으로 인공지능이 어떻게 발전하게 될까요? 사람에 따라 다르겠지요.\n",
            "앞으로 인공지능이 어떻게 발전하게 될까요? 인공지능이 발달함에 따라 좀 더 똑똑해 질거예요. 인공지능을 이해하면 가능하죠.\n",
            "앞으로 인공지능이 어떻게 발전하게 될까요? 인공지능은 사람을 따라하게 될지도 몰라요. 인공지능의 발달에 맞춰 인공지능의 발달에 맞춰 준비를 해야겠죠.\n",
            "앞으로 인공지능이 어떻게 발전하게 될까요? 인공지능은 사람을 대신할 수 없어요. 인공지능은 더 똑똑해 질 거예요.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjwQ02NfxuSE",
        "outputId": "584bb94b-2cdb-4343-e058-9fdd0c71d521"
      },
      "source": [
        "get_answer('이제 그만 수업 끝내자.')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이제 그만 수업 끝내자. 심호흡을 해보세요.\n",
            "이제 그만 수업 끝내자. 마무리 잘하세요.\n",
            "이제 그만 수업 끝내자. 너무 힘든 건 아닌지 확인해보세요.\n",
            "이제 그만 수업 끝내자. 차분히 생각해요.\n",
            "이제 그만 수업 끝내자. 다음 학기를 준비하고 미리 걱정마세요.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EwSHUQKXkgI",
        "outputId": "e00c8ced-f69e-49b2-c5ce-7ee956e28fea"
      },
      "source": [
        "get_answer('한국과 북한의 관계는?')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "한국과 북한의 관계는? 남과 북의 관계는 어떻게 해보세요?\n",
            "한국과 북한의 관계는? 서로 알아가는 단계인가봐요.\n",
            "한국과 북한의 관계는? 잘 아시죠.\n",
            "한국과 북한의 관계는? 현재와 미래가 선순환을 이루는 관계가 좋아요.\n",
            "한국과 북한의 관계는? 서로 이해하고 배려하면 될 거예요.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDJnfWTjXpNp",
        "outputId": "d4fc986b-7712-4aec-e30b-9d0bf4a5cfcc"
      },
      "source": [
        "get_answer('손흥민의 소속팀은?')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "손흥민의 소속팀은? 바로 독일로 돌아가서 열심히 노력하겠습니다.\n",
            "손흥민의 소속팀은? 다음에는 어디서 만나도 괜찮아요.\n",
            "손흥민의 소속팀은? 곧 결정날거예요.\n",
            "손흥민의 소속팀은? 제가 있잖아요.\n",
            "손흥민의 소속팀은? 현재 독일 분데스리가에 있는 함부르크에서 뛰고 있는 손흥민을 찾아보세요.\n"
          ]
        }
      ]
    }
  ]
}